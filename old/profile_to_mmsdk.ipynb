{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from mmsdk import mmdatasdk\n",
    "import numpy\n",
    "import pandas\n",
    "import h5py\n",
    "import tqdm\n",
    "import skimage.io\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "from scipy.io import wavfile\n",
    "import librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fr = 29.97\n",
    "ft = 1 / fr\n",
    "print(ft)\n",
    "sr = 11025\n",
    "spf = round(ft * sr)\n",
    "print(spf)\n",
    "profile = \"obama\"\n",
    "root = \"/home/santiago/Data/deep_puppetry/{}\".format(profile)\n",
    "out_dir =\"/home/santiago/Data/deep_puppetry/csd/{}\".format(profile)\n",
    "videos = sorted(os.listdir(root))\n",
    "print(videos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_openface(video, start, end):\n",
    "    openface_df = pandas.read_csv(os.path.join(root, video, \"processed/{}.csv\".format(video)), sep=\", \")\n",
    "    intervals = []\n",
    "    features = []\n",
    "    t = start\n",
    "    for i, row in openface_df.iterrows():\n",
    "        timestamp = float(row[\"timestamp\"])\n",
    "        if timestamp >= start and timestamp <= end:\n",
    "            intervals.append([t, timestamp])\n",
    "            features.append(row.values[5:])\n",
    "            t = timestamp\n",
    "    return numpy.array(intervals), numpy.array(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_frames(video, start, end):\n",
    "    openface_df = pandas.read_csv(os.path.join(root, video, \"processed/{}.csv\".format(video)), sep=\", \")\n",
    "    intervals = []\n",
    "    features = []\n",
    "    t = start\n",
    "    for file in sorted(glob.glob(os.path.join(root, video, \"processed/{}_aligned/*.bmp\".format(video)))):\n",
    "        frame = int(file[-10:-4])\n",
    "        timestamp = float(openface_df.loc[openface_df[\"frame\"] == frame].iloc[0][\"timestamp\"])\n",
    "        confidence = float(openface_df.loc[openface_df[\"frame\"] == frame].iloc[0][\"confidence\"])\n",
    "        if timestamp >= start and timestamp <= end and confidence >= 0.9:\n",
    "            img = skimage.io.imread(file)\n",
    "            intervals.append([t, timestamp])\n",
    "            features.append(img.flatten())\n",
    "        t = timestamp\n",
    "    return numpy.array(intervals), numpy.array(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_frames10(video, start, end):\n",
    "    start = round(start * fr)\n",
    "    end = round(end * fr)\n",
    "    intervals = []\n",
    "    features = []\n",
    "    t = start / fr\n",
    "    for file in sorted(glob.glob(os.path.join(root, video, \"processed/{}_aligned/*.bmp\".format(video)))):\n",
    "        frame = int(file[-10:-4])\n",
    "        if frame >= start and frame <= end and frame % 3 == 0:\n",
    "            img = skimage.io.imread(file)\n",
    "            timestamp = frame / fr\n",
    "            intervals.append([t, timestamp])\n",
    "            features.append(img.flatten())\n",
    "            t = timestamp\n",
    "    return numpy.array(intervals), numpy.array(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_words(video):\n",
    "    data = h5py.File(os.path.join(root, video, \"AlignFilter/{}_words.hdf5\".format(video)))[video]\n",
    "    intervals = list(data[\"intervals\"])\n",
    "    features = list(data[\"features\"])\n",
    "    return numpy.array(intervals), numpy.array(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_phones(video):\n",
    "    data = h5py.File(os.path.join(root, video, \"AlignFilter/{}_phones.hdf5\".format(video)))[video]\n",
    "    intervals = list(data[\"intervals\"])\n",
    "    features = list(data[\"features\"])\n",
    "    return numpy.array(intervals), numpy.array(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_spectrograms(video, start, end):\n",
    "    intervals = []\n",
    "    features = []\n",
    "    t = start\n",
    "    spectrogram = numpy.load(os.path.join(root, video, \"spectrogram.npy\"))\n",
    "    for i, spectro in enumerate(spectrogram.T):\n",
    "        timestamp = i * ft\n",
    "        if timestamp >= start and timestamp <= end:\n",
    "            spectro = numpy.stack([spectro.real, spectro.imag])\n",
    "            intervals.append([t, timestamp])\n",
    "            features.append(spectro.flatten())\n",
    "            t = timestamp\n",
    "    return numpy.array(intervals), numpy.array(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def read_spectrograms(video, start, end):\n",
    "#     openface_df = pandas.read_csv(os.path.join(root, video, \"processed/{}.csv\".format(video)), sep=\", \")\n",
    "#     intervals = []\n",
    "#     features = []\n",
    "#     t = start\n",
    "#     for file in sorted(glob.glob(os.path.join(root, video, \"spectrograms/*.npy\"))):\n",
    "#         frame = int(file[-9:-4])\n",
    "#         timestamp = float(openface_df.loc[openface_df[\"frame\"] == frame].iloc[0][\"timestamp\"])\n",
    "#         if timestamp >= start and timestamp <= end:\n",
    "#             arr = numpy.load(file)\n",
    "#             intervals.append([t, timestamp])\n",
    "#             features.append(arr.flatten())\n",
    "#             t = timestamp\n",
    "#     return numpy.array(intervals), numpy.array(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_data = {}\n",
    "for video in tqdm.tqdm(videos):\n",
    "    word_intervals, word_features = read_words(video)\n",
    "    word_data[video] = {}\n",
    "    word_data[video][\"intervals\"] = word_intervals\n",
    "    word_data[video][\"features\"] = word_features\n",
    "words = mmdatasdk.computational_sequence(\"{}_words\".format(profile))\n",
    "words.setData(word_data, root)\n",
    "words.deploy(os.path.join(out_dir, \"{}_words.csd\").format(profile))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phone_data = {}\n",
    "for video in tqdm.tqdm(videos):\n",
    "    phone_intervals, phone_features = read_phones(video)\n",
    "    phone_data[video] = {}\n",
    "    phone_data[video][\"intervals\"] = phone_intervals\n",
    "    phone_data[video][\"features\"] = phone_features\n",
    "phones = mmdatasdk.computational_sequence(\"{}_phones\".format(profile))\n",
    "phones.setData(phone_data, root)\n",
    "phones.deploy(os.path.join(out_dir, \"{}_phones.csd\").format(profile))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openface_data = {}\n",
    "for video in tqdm.tqdm(videos):\n",
    "    phone_intervals = list(h5py.File(os.path.join(root, video, \"AlignFilter/{}_phones.hdf5\".format(video)))[video][\"intervals\"])\n",
    "    start = phone_intervals[0][0]\n",
    "    end = phone_intervals[-1][1]\n",
    "    openface_intervals, openface_features = read_openface(video, start, end)\n",
    "    openface_data[video] = {}\n",
    "    openface_data[video][\"intervals\"] = openface_intervals\n",
    "    openface_data[video][\"features\"] = openface_features\n",
    "openface = mmdatasdk.computational_sequence(\"{}_openface\".format(profile))\n",
    "openface.setData(openface_data, root)\n",
    "openface.deploy(os.path.join(out_dir, \"{}_openface.csd\".format(profile)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_data = {}\n",
    "for video in tqdm.tqdm(videos):\n",
    "    phone_intervals = list(h5py.File(os.path.join(root, video, \"AlignFilter/{}_phones.hdf5\".format(video)))[video][\"intervals\"])\n",
    "    start = phone_intervals[0][0]\n",
    "    end = phone_intervals[-1][1]\n",
    "    frame_intervals, frame_features = read_frames(video, start, end)\n",
    "    frame_data[video] = {}\n",
    "    frame_data[video][\"intervals\"] = frame_intervals\n",
    "    frame_data[video][\"features\"] = frame_features\n",
    "frames = mmdatasdk.computational_sequence(\"{}_frames\".format(profile))\n",
    "frames.setData(frame_data, root)\n",
    "frames.deploy(os.path.join(out_dir, \"{}_frames.csd\".format(profile)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame10_data = {}\n",
    "for video in tqdm.tqdm(videos):\n",
    "    phone_intervals = list(h5py.File(os.path.join(root, video, \"AlignFilter/{}_phones.hdf5\".format(video)))[video][\"intervals\"])\n",
    "    start = phone_intervals[0][0]\n",
    "    end = phone_intervals[-1][1]\n",
    "    frame10_intervals, frame10_features = read_frames10(video, start, end)\n",
    "    frame10_data[video] = {}\n",
    "    frame10_data[video][\"intervals\"] = frame10_intervals\n",
    "    frame10_data[video][\"features\"] = frame10_features\n",
    "frames10 = mmdatasdk.computational_sequence(\"{}_frames10\".format(profile))\n",
    "frames10.setData(frame10_data, root)\n",
    "frames10.deploy(os.path.join(out_dir, \"{}_frames10.csd\".format(profile)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectrogram_data = {}\n",
    "for video in tqdm.tqdm(videos):\n",
    "    phone_intervals = list(h5py.File(os.path.join(root, video, \"AlignFilter/{}_phones.hdf5\".format(video)))[video][\"intervals\"])\n",
    "    start = phone_intervals[0][0]\n",
    "    end = phone_intervals[-1][1]\n",
    "    spectrogram_intervals, spectrogram_features = read_spectrograms(video, start, end)\n",
    "    spectrogram_data[video] = {}\n",
    "    spectrogram_data[video][\"intervals\"] = spectrogram_intervals\n",
    "    spectrogram_data[video][\"features\"] = spectrogram_features\n",
    "spectrograms = mmdatasdk.computational_sequence(\"{}_spectrograms\".format(profile))\n",
    "spectrograms.setData(spectrogram_data, root)\n",
    "spectrograms.deploy(os.path.join(out_dir, \"{}_spectrograms.csd\".format(profile)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create spectrograms\n",
    "for video in tqdm.tqdm(videos):\n",
    "    samples, rate = librosa.core.load(os.path.join(root, video, \"{}.wav\".format(video)), sr=sr, mono=True, dtype=numpy.float32)\n",
    "    assert rate == sr\n",
    "    frequencies, times, spectrogram = signal.stft(samples, fs=rate, nperseg=spf*2)\n",
    "    numpy.save(os.path.join(root, video, \"spectrogram.npy\"), spectrogram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # create spectrograms\n",
    "# for video in tqdm.tqdm(videos):\n",
    "# #     d = os.path.join(root, video, \"spectrograms\")\n",
    "# #     if not os.path.exists(d):\n",
    "# #         os.mkdir(d)\n",
    "# #     rate, samples = wavfile.read(os.path.join(root, video, \"{}.wav\".format(video)))\n",
    "#     samples, rate = librosa.core.load(os.path.join(root, video, \"{}.wav\".format(video)), sr=sr, mono=True, dtype=numpy.float32)\n",
    "#     assert rate == sr\n",
    "# #     assert len(samples.shape) == 1\n",
    "# #     openface_df = pandas.read_csv(os.path.join(root, video, \"processed/{}.csv\".format(video)), sep=\", \")\n",
    "# #     frames = []\n",
    "#     spectrograms = []\n",
    "#     remainder = len(samples) % spf\n",
    "#     if remainder > 0:\n",
    "#         samples = samples[:-remainder]\n",
    "#     chunks = len(samples) // spf\n",
    "#     for chunk in numpy.split(samples, chunks):\n",
    "#         frequencies, times, spectrogram = signal.stft(chunk, fs=rate, nperseg=spf//4)\n",
    "#         spectrogram = numpy.stack([spectrogram.real, spectrogram.imag])\n",
    "#     #     assert spectrogram.shape == (2, 62, 8)\n",
    "#         assert spectrogram.shape == (2, 47, 9)\n",
    "#         spectrograms.append(spectrogram)\n",
    "#     spectrograms = numpy.stack(spectrograms)\n",
    "#     numpy.save(os.path.join(root, video, \"spectrograms.npy\"), spectrograms)\n",
    "# #         print(spectrogram.shape)\n",
    "# #     for i, row in openface_df.iterrows():\n",
    "# #         t = float(row[\"timestamp\"])\n",
    "# #         f = int(row[\"frame\"])\n",
    "# #         frequencies, times, spectrogram = signal.stft(samples[round(rate*t):round(rate*(t+ft))], fs=rate, nperseg=nps)\n",
    "# #         spectrogram = numpy.stack([spectrogram.real, spectrogram.imag])\n",
    "# #         if spectrogram.shape == (2, 62, 8):\n",
    "# #             frames.append(f)\n",
    "# #             spectrograms.append(spectrogram)\n",
    "# #         else:\n",
    "# #             print(\"Skipped\", video, f)\n",
    "# #     spectrograms = numpy.stack(spectrograms)\n",
    "# #     assert spectrograms.dtype == numpy.float32\n",
    "# #     spectrograms = skimage.exposure.rescale_intensity(spectrograms)\n",
    "# #     for f, spectrogram in zip(frames, spectrograms):\n",
    "# #         numpy.save(os.path.join(d, \"frame_{:05d}.npy\".format(f)), spectrogram)\n",
    "# #         skimage.io.imsave(os.path.join(d, \"frame_{:05d}.tif\".format(f)), spectrogram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # test spectrograms\n",
    "# for video in tqdm.tqdm(videos):\n",
    "#     d = os.path.join(root, video, \"spectrograms\")\n",
    "#     samples = []\n",
    "#     for f in os.listdir(d):\n",
    "#         f = os.path.join(d, f)\n",
    "#         spectrogram = numpy.load(f)\n",
    "#         Zxx = numpy.zeros_like(spectrogram[0], dtype=numpy.complex64)\n",
    "#         Zxx.real = spectrogram[0]\n",
    "#         Zxx.imag = spectrogram[1]\n",
    "#         t, x = signal.istft(Zxx, fs=sr, nperseg=nps)\n",
    "#         samples.append(x)\n",
    "#     samples = numpy.concatenate(samples, axis=-1)\n",
    "#     wavfile.write(os.path.join(d, \"test.wav\"), sr, samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# samples, rate = librosa.core.load(\"/home/santiago/Data/deep_puppetry/obama/0SaVqB0w718/0SaVqB0w718.wav\", sr=sr, mono=True, dtype=numpy.float32)\n",
    "# assert rate == sr\n",
    "# assert len(samples.shape) == 1\n",
    "# # openface_df = pandas.read_csv(os.path.join(root, \"0SaVqB0w718\", \"processed/0SaVqB0w718.csv\"), sep=\", \")\n",
    "# # frames = []\n",
    "# spectrograms = []\n",
    "# remainder = len(samples) % spf\n",
    "# samples = samples[:-remainder]\n",
    "# chunks = len(samples) // spf\n",
    "# for i, chunk in enumerate(numpy.split(samples, chunks)):\n",
    "#     frequencies, times, spectrogram = signal.stft(samples[i*spf:(i+1)*spf], fs=rate, nperseg=spf//4)\n",
    "#     spectrogram = numpy.stack([spectrogram.real, spectrogram.imag])\n",
    "# #     assert spectrogram.shape == (2, 62, 8)\n",
    "#     spectrograms.append(spectrogram)\n",
    "#     print(spectrogram.shape)\n",
    "# #     if spectrogram.shape == (2, 62, 8):\n",
    "# #         frames.append(f)\n",
    "# #         spectrograms.append(spectrogram)\n",
    "# #     else:\n",
    "# #         print(\"Skipped\", i)\n",
    "# # for i, row in openface_df.iterrows():\n",
    "# #     t = float(row[\"timestamp\"])\n",
    "# #     f = int(row[\"frame\"])\n",
    "# #     frequencies, times, spectrogram = signal.stft(samples[round(rate*t):round(rate*(t+ft))], fs=rate, nperseg=nps)\n",
    "# #     spectrogram = numpy.stack([spectrogram.real, spectrogram.imag])\n",
    "# # #     print(spectrogram)\n",
    "# #     if spectrogram.shape == (2, 62, 8) and spectrogram.dtype == numpy.float32:\n",
    "# #         frames.append(f)\n",
    "# #         spectrograms.append(spectrogram)\n",
    "# #     else:\n",
    "# #         print(\"Skipped\", f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recon = []\n",
    "# for i, spectrogram in enumerate(spectrograms):\n",
    "# #     print(spectrogram.dtype)\n",
    "#     Zxx = numpy.zeros_like(spectrogram[0], dtype=numpy.complex64)\n",
    "#     Zxx.real = spectrogram[0]\n",
    "#     Zxx.imag = spectrogram[1]\n",
    "#     t, x = signal.istft(Zxx, fs=rate, nperseg=spf//4)\n",
    "# #     print(x.shape)\n",
    "# #     print(x.dtype)\n",
    "#     recon.append(x)\n",
    "# #     samples.append(x.astype(numpy.float32))\n",
    "# recon = numpy.concatenate(recon, axis=-1)\n",
    "# print(recon.dtype)\n",
    "# # IPython.display.Audio(data=samples, rate=sr)\n",
    "# wavfile.write(\"test.wav\", sr, recon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identity = \"trump\"\n",
    "# dset = \"phones\"\n",
    "# f = h5py.File(\"/home/santiago/Downloads/deep_puppetry/csd/{}/{}_{}.csd\".format(identity, identity, dset), \"r+\")\n",
    "# f[\"{}_{}\".format(identity, dset)] = f[\"{}\".format(identity)]\n",
    "# del f[\"{}\".format(identity)]\n",
    "# f[\"{}_{}\".format(identity, dset)][\"metadata\"][\"root name\"][...] = numpy.array([\"{}_{}\".format(identity, dset)], dtype=object)\n",
    "# f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# root_dir = \"/home/santiago/Data/deep_puppetry/obama/\"\n",
    "# videos = dict.fromkeys(os.listdir(root_dir))\n",
    "# for video in tqdm.tqdm(videos.keys()):\n",
    "#     videos[video] = {}\n",
    "#     openface = pandas.read_csv(os.path.join(root_dir, video, \"processed/{}.csv\".format(video)), sep=\", \", index_col=False)\n",
    "#     videos[video][\"openface\"] = openface[openface[\"frame\"] % 3 == 0]\n",
    "#     frames = sorted(glob.glob(os.path.join(root_dir, video, \"processed/{}_aligned/*.bmp\".format(video))))\n",
    "#     videos[video][\"frames\"] = list(filter(lambda x: int(x[-10:-4]) in videos[video][\"openface\"][\"frame\"].values, frames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# from scipy import signal\n",
    "# from scipy.io import wavfile\n",
    "# import librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# samples, rate = librosa.load(\"/home/santiago/Data/deep_puppetry/obama/0SaVqB0w718/0SaVqB0w718.wav\", sr=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(samples[round(rate*25.000):round(rate*25.033)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# frequencies, times, spectrogram = signal.spectrogram(samples[round(rate*30):round(rate*30.033)], rate, nperseg=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spectrogram.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# skimage.io.imshow(spectrogram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.pcolormesh(times, frequencies, spectrogram)\n",
    "# plt.imshow(spectrogram)\n",
    "# plt.ylabel('Frequency [Hz]')\n",
    "# plt.xlabel('Time [sec]')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pandas.read_csv(\"/home/santiago/Data/deep_puppetry/obama/0SaVqB0w718/processed/0SaVqB0w718.csv\", sep=\", \")\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for video in videos:\n",
    "#     rate, samples = wavfile.read(os.path.join(root, video, \"{}.wav\".format(video)))\n",
    "#     print(rate, len(samples))\n",
    "#     frequencies, times, spectrogram = signal.spectrogram(samples[round(rate*200):round(rate*(200.0+ft))], rate, nperseg=50)\n",
    "#     print(frequencies)\n",
    "#     print(spectrogram.shape)\n",
    "#     skimage.io.imshow(spectrogram)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, row in df.iterrows():\n",
    "#     print(row[\"frame\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import IPython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
